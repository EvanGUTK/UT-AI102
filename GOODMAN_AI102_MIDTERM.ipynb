{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93a443-bc36-4e10-af65-632893109b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()\n",
    "#Load book module\n",
    "from nltk.book import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e1bb80-83d6-43ae-a68a-d670b5f104c8",
   "metadata": {},
   "source": [
    "# Q1 - 10 pts\n",
    "Define a variable `sent` to contain the string: \"newly formed bland ideas are inexpressible in an infuriating way\". \n",
    "Write code to perform the following tasks:\n",
    "- Print the words of `sent` in alphabetical order, one per line.\n",
    "- Split `sent` into a list of strings, one per word, using Python’s `split()` operation, and save this to a variable called `wordList`.\n",
    "- Extract the second letter of each word in `wordList` and join them into a string, to get 'eoldrnnnna'.\n",
    "- Combine the words in `wordList` back into a single string, using `join()`. Make sure the words in the resulting string are separated with whitespace.\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b61e2f-5e10-491a-8c90-5b5ac92af49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question 1\n",
      "an\n",
      "are\n",
      "bland\n",
      "formed\n",
      "ideas\n",
      "in\n",
      "inexpressible\n",
      "infuriating\n",
      "newly\n",
      "way\n",
      "\n",
      "Second Letter String: eoldrnnnna\n",
      "\n",
      "Original: newly formed bland ideas are inexpressible in an infuriating way\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuestion 1\")\n",
    "\n",
    "sent = (\"\\nnewly formed bland ideas are inexpressible in an infuriating way\")\n",
    "\n",
    "for word in sorted(sent.split()):\n",
    "    print(word)\n",
    "\n",
    "wordlist = sent.split()\n",
    "\n",
    "second = ''.join(word[1] for word in wordlist)\n",
    "print(\"\\nSecond Letter String:\", letters)\n",
    "\n",
    "Original = ' '.join(wordlist)\n",
    "print(\"\\nOriginal:\", Origi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9865666-36b9-41e3-8b4f-eb43f731cb54",
   "metadata": {},
   "source": [
    "# Q2 - 5 pts\n",
    "\n",
    "Define the variable `strList` to contain the list:\n",
    "\n",
    "['After', 'all', 'is', 'said','and', 'done', ',', 'more', 'is', 'said', 'than', 'done', '.']\n",
    "\n",
    "\n",
    "\n",
    "Process the list using a `for loop`, and store the length of each word in `strList` in a new list, `lengths`. Hint: begin by assigning the empty list to `lengths`. Then each time through the loop, use `append()` to add another length value to the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cbf0f97-7e3a-4a86-99af-c204a5a8d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2\n",
      "[5, 3, 2, 4, 3, 4, 1, 4, 2, 4, 4, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Question 2\")\n",
    "\n",
    "strList = ['After', 'all', 'is', 'said', 'and', 'done', ',', 'more', 'is', 'said', 'than', 'done', '.']\n",
    "\n",
    "lengths = []\n",
    "\n",
    "for word in strList:\n",
    "    lengths.append(len(word))\n",
    "\n",
    "print(lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7e669-a2a1-4e4b-9e0b-20202c3d356f",
   "metadata": {},
   "source": [
    "# Q3  - 7 pts\n",
    "- Define a string  aString = \"colorless\". Write a Python statement that changes this to\n",
    "“colourless” using only the slice and concatenation (+) operations.\n",
    "- We can use the slice notation to remove morphological endings on words. For\n",
    "example, slicing [:-1] when applied to \"dogs\" removes the last character of \"dogs\", leaving \"dog\". Use slice\n",
    "notation to remove the affixes from the following words (a hyphen is used to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b282ed4-b02a-4246-8475-8dbe9350b16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 3\n",
      "\n",
      "Part 1\n",
      "\n",
      "colourless\n",
      "\n",
      "Part 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 17\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPart 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdishes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrunning\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnationality\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mundo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreheat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m word \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     16\u001b[0m     word[\u001b[38;5;241m0\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m---> 17\u001b[0m     word[\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m],\n\u001b[0;32m     18\u001b[0m     word[\u001b[38;5;241m2\u001b[39m][:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m     19\u001b[0m     word[\u001b[38;5;241m3\u001b[39m][\u001b[38;5;241m2\u001b[39m:], \n\u001b[0;32m     20\u001b[0m     word[\u001b[38;5;241m4\u001b[39m][\u001b[38;5;241m3\u001b[39m:] \n\u001b[0;32m     21\u001b[0m ]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(word)\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "print(\"Question 3\")\n",
    "\n",
    "print(\"\\nPart 1\")\n",
    "\n",
    "aString = (\"\\ncolorless\")\n",
    "\n",
    "aString = aString[:5] +'u'+ aString[5:]\n",
    "\n",
    "print(aString)\n",
    "\n",
    "print(\"\\nPart 2\")\n",
    "\n",
    "words = [\"dishes\", \"running\", \"nationality\", \"undo\", \"preheat\"]\n",
    "\n",
    "word = [\n",
    "    word[0][:-2],\n",
    "    word[1][:-3],\n",
    "    word[2][:-5],\n",
    "    word[3][2:], \n",
    "    word[4][3:] \n",
    "]\n",
    "\n",
    "print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b7f24a-fe18-4e5a-9a97-8eedcb84db86",
   "metadata": {},
   "source": [
    "# Q4 - 4pts\n",
    "Use the `book` module to explore `Sense and Sensibility` by Jane Austen. How many word tokens does this book have? Use `.isalpha()` to filter out special symbols and punctuation marks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea7541f5-f27c-44de-9cf1-178ae8fc5f45",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text2\n\u001b[0;32m      4\u001b[0m words \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text2 \u001b[38;5;28;01mif\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalpha()] \n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py:180\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download, download_shell\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\downloader.py:2475\u001b[0m\n\u001b[0;32m   2465\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;66;03m# Main:\u001b[39;00m\n\u001b[0;32m   2470\u001b[0m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2473\u001b[0m \n\u001b[0;32m   2474\u001b[0m \u001b[38;5;66;03m# Aliases\u001b[39;00m\n\u001b[1;32m-> 2475\u001b[0m _downloader \u001b[38;5;241m=\u001b[39m Downloader()\n\u001b[0;32m   2476\u001b[0m download \u001b[38;5;241m=\u001b[39m _downloader\u001b[38;5;241m.\u001b[39mdownload\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_shell\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\downloader.py:515\u001b[0m, in \u001b[0;36mDownloader.__init__\u001b[1;34m(self, server_index_url, download_dir)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# decide where we're going to save things to.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_download_dir()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\downloader.py:1068\u001b[0m, in \u001b[0;36mDownloader.default_download_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# Check if we have sufficient permissions to install in a\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;66;03m# variety of system-wide locations.\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nltkdir \u001b[38;5;129;01min\u001b[39;00m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(nltkdir) \u001b[38;5;129;01mand\u001b[39;00m nltk\u001b[38;5;241m.\u001b[39minternals\u001b[38;5;241m.\u001b[39mis_writable(nltkdir):\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nltkdir\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import text2\n",
    "\n",
    "words = [word for word in text2 if word.isalpha()] \n",
    "\n",
    "tokens = len(words)\n",
    "\n",
    "print(\"Total tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3cb29-3263-493d-9b50-4f43d2ebd7de",
   "metadata": {},
   "source": [
    "# Q5  - 4pts\n",
    "Using dispersion plot visualize the occurrences of men, women, and people in Inaugural Address Corpus. What has\n",
    "happened to the usage of these words over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9b6bbdf-2282-4c6e-99fa-14f2d5bee390",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text4\n\u001b[0;32m      4\u001b[0m target_words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwomen\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeople\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\__init__.py:180\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster\n\u001b[1;32m--> 180\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download, download_shell\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\downloader.py:2475\u001b[0m\n\u001b[0;32m   2465\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   2468\u001b[0m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[0;32m   2469\u001b[0m \u001b[38;5;66;03m# Main:\u001b[39;00m\n\u001b[0;32m   2470\u001b[0m \u001b[38;5;66;03m######################################################################\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2473\u001b[0m \n\u001b[0;32m   2474\u001b[0m \u001b[38;5;66;03m# Aliases\u001b[39;00m\n\u001b[1;32m-> 2475\u001b[0m _downloader \u001b[38;5;241m=\u001b[39m Downloader()\n\u001b[0;32m   2476\u001b[0m download \u001b[38;5;241m=\u001b[39m _downloader\u001b[38;5;241m.\u001b[39mdownload\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_shell\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\downloader.py:515\u001b[0m, in \u001b[0;36mDownloader.__init__\u001b[1;34m(self, server_index_url, download_dir)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;66;03m# decide where we're going to save things to.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_download_dir()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\downloader.py:1068\u001b[0m, in \u001b[0;36mDownloader.default_download_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;66;03m# Check if we have sufficient permissions to install in a\u001b[39;00m\n\u001b[0;32m   1067\u001b[0m \u001b[38;5;66;03m# variety of system-wide locations.\u001b[39;00m\n\u001b[1;32m-> 1068\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nltkdir \u001b[38;5;129;01min\u001b[39;00m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mpath:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(nltkdir) \u001b[38;5;129;01mand\u001b[39;00m nltk\u001b[38;5;241m.\u001b[39minternals\u001b[38;5;241m.\u001b[39mis_writable(nltkdir):\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m nltkdir\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'nltk' has no attribute 'data' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import text4\n",
    "\n",
    "target_words = [\"men\", \"women\", \"people\"]\n",
    "\n",
    "text4.dispersion_plot(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcadf1ea-f8a3-445a-839a-7f619d4e8019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
