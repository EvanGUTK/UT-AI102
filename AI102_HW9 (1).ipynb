{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7460c60-378d-4141-8aad-f9481814c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part1\n",
    "#Parsing using a simple grammar\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "\n",
    "NP -> Det N | Det Adj N | NP PP\n",
    "\n",
    "VP -> V | V NP | VP PP\n",
    "\n",
    "PP -> P NP\n",
    "\n",
    "Det -> 'the' | 'a' | 'an'\n",
    "Adj -> 'big' | 'small' | 'brown'|'furry'|'sweet'|\n",
    "N -> 'cat' | 'dog' | 'car' | 'house' | 'boy' | 'girl'\n",
    "V -> 'sleeps' | 'eats' | 'chased' | 'found' | 'sat'| 'ran'\n",
    "P -> 'on' | 'in' | 'under' | 'with'\n",
    "\"\"\")\n",
    "#Parse 3 different sentences and display their parse trees\n",
    "#Note that you need to install and import svgling library given in the example notebook\n",
    "#Discuss the limitations of the grammar above. Give an example of text that can't be parsed using this grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5319a26e-0c36-403b-b253-49def11d6e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed tree for: the big dog chased the cat\n",
      "         S                    \n",
      "      ___|__________           \n",
      "     |              VP        \n",
      "     |         _____|___       \n",
      "     NP       |         NP    \n",
      "  ___|___     |      ___|___   \n",
      "Det Adj  N    V    Det      N \n",
      " |   |   |    |     |       |  \n",
      "the big dog chased the     cat\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Parse and show trees\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m [sent1, sent2, sent3]:\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mparse(sent):\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsed tree for:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sent))\n\u001b[0;32m     30\u001b[0m         tree\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:130\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:168\u001b[0m, in \u001b[0;36mRecursiveDescentParser._match\u001b[1;34m(self, rtext, tree, frontier)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_match(newtree, frontier[\u001b[38;5;241m1\u001b[39m:], rtext[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(rtext[\u001b[38;5;241m1\u001b[39m:], newtree, frontier[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# If it's a non-matching terminal, fail.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:130\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:168\u001b[0m, in \u001b[0;36mRecursiveDescentParser._match\u001b[1;34m(self, rtext, tree, frontier)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_match(newtree, frontier[\u001b[38;5;241m1\u001b[39m:], rtext[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(rtext[\u001b[38;5;241m1\u001b[39m:], newtree, frontier[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# If it's a non-matching terminal, fail.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:130\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:168\u001b[0m, in \u001b[0;36mRecursiveDescentParser._match\u001b[1;34m(self, rtext, tree, frontier)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_match(newtree, frontier[\u001b[38;5;241m1\u001b[39m:], rtext[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(rtext[\u001b[38;5;241m1\u001b[39m:], newtree, frontier[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# If it's a non-matching terminal, fail.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "    \u001b[1;31m[... skipping similar frames: RecursiveDescentParser._expand at line 225 (982 times), RecursiveDescentParser._parse at line 126 (982 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:126\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a tree, expand it.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree[frontier[\u001b[38;5;241m0\u001b[39m]], Tree):\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:225\u001b[0m, in \u001b[0;36mRecursiveDescentParser._expand\u001b[1;34m(self, remaining_text, tree, frontier, production)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace:\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_expand(newtree, new_frontier, production)\n\u001b[1;32m--> 225\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse(\n\u001b[0;32m    226\u001b[0m     remaining_text, newtree, new_frontier \u001b[38;5;241m+\u001b[39m frontier[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    227\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:130\u001b[0m, in \u001b[0;36mRecursiveDescentParser._parse\u001b[1;34m(self, remaining_text, tree, frontier)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand(remaining_text, tree, frontier)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# If the next element on the frontier is a token, match it.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match(remaining_text, tree, frontier)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\parse\\recursivedescent.py:160\u001b[0m, in \u001b[0;36mRecursiveDescentParser._match\u001b[1;34m(self, rtext, tree, frontier)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_match\u001b[39m(\u001b[38;5;28mself\u001b[39m, rtext, tree, frontier):\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    :rtype: iter(Tree)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    :return: an iterator of all parses that can be generated by\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m        leaves that have not yet been matched.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     tree_leaf \u001b[38;5;241m=\u001b[39m tree[frontier[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rtext) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m tree_leaf \u001b[38;5;241m==\u001b[39m rtext[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;66;03m# If it's a terminal that matches rtext[0], then substitute\u001b[39;00m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;66;03m# in the token, and continue parsing.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m         newtree \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tree\\tree.py:162\u001b[0m, in \u001b[0;36mTree.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]][index[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m indices must be integers, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(index)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    167\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tree\\tree.py:162\u001b[0m, in \u001b[0;36mTree.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]][index[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m indices must be integers, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(index)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    167\u001b[0m     )\n",
      "    \u001b[1;31m[... skipping similar frames: Tree.__getitem__ at line 162 (983 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tree\\tree.py:162\u001b[0m, in \u001b[0;36mTree.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]][index[\u001b[38;5;241m1\u001b[39m:]]\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m indices must be integers, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mtype\u001b[39m(index)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    167\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\tree\\tree.py:160\u001b[0m, in \u001b[0;36mTree.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[index[\u001b[38;5;241m0\u001b[39m]][index[\u001b[38;5;241m1\u001b[39m:]]\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.parse import RecursiveDescentParser\n",
    "\n",
    "grammar = CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Det N | Det Adj N | NP PP\n",
    "VP -> V | V NP | VP PP\n",
    "PP -> P NP\n",
    "Det -> 'the' | 'a' | 'an'\n",
    "Adj -> 'big' | 'small' | 'brown' | 'furry' | 'sweet'\n",
    "N -> 'cat' | 'dog' | 'car' | 'house' | 'boy' | 'girl'\n",
    "V -> 'sleeps' | 'eats' | 'chased' | 'found' | 'sat' | 'ran'\n",
    "P -> 'on' | 'in' | 'under' | 'with'\n",
    "\"\"\")\n",
    "\n",
    "parser = RecursiveDescentParser(grammar)\n",
    "\n",
    "sent1 = \"the big dog chased the cat\".split()\n",
    "sent2 = \"a boy sat on the car\".split()\n",
    "sent3 = \"the furry cat sleeps in the house\".split()\n",
    "\n",
    "for sent in [sent1, sent2, sent3]:\n",
    "    for tree in parser.parse(sent):\n",
    "        print(\"Parsed tree for:\", ' '.join(sent))\n",
    "        tree.pretty_print()\n",
    "        print()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a2277ce-0df3-4e2f-b46e-98cb2a3fdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part2\n",
    "#Using regular expressions extract dates in any of the following formats: DD/MM/YYYY,  D/M/YY, M/DD/YYYY or YY/MM/DD \n",
    "# and email addresses from a given text. Your sample text for testing your code should also have dates and  in formats other than those above \n",
    "# to show that they won't be extracted.\n",
    "# Note that a valid email address follows the structure local-part@domain, where \"local-part\" is the username and \n",
    "#\"domain\" is the email provider or domain name. The @ symbol is crucial, separating the username from the domain. \n",
    "#For example, john.doe@example.com is a valid email address. '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3b59b0f-c7ee-460e-962d-9ed08c088e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID DATES FOUND:\n",
      " - 05/11/2003\n",
      " - 05/10/2026\n",
      " - 12/13/2020\n",
      "\n",
      "VALID EMAILS FOUND:\n",
      " - john.doe@example.com\n",
      " - evan@uni.edu\n",
      " - hello.world-123@company.net\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"\n",
    "My birthday is 05/11/2003. I expect to graduate 05/10/2026\n",
    "More dates: 30-04-1998, 04.21.21, 12/13/2020.\n",
    "Emails: john.doe@example.com, not.real@email, noatsign.com, evan@uni.edu\n",
    "Another one: hello.world-123@company.net\n",
    "\"\"\"\n",
    "\n",
    "date_pattern = r'\\b(?:\\d{2}/\\d{2}/\\d{4}|\\d{1}/\\d{1}/\\d{2}|\\d{1,2}/\\d{2}/\\d{4}|\\d{2}/\\d{2}/\\d{2})\\b'\n",
    "email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b'\n",
    "\n",
    "valid_dates = re.findall(date_pattern, text)\n",
    "valid_emails = re.findall(email_pattern, text)\n",
    "\n",
    "print(\"VALID DATES FOUND:\")\n",
    "for date in valid_dates:\n",
    "    print(\" -\", date)\n",
    "\n",
    "print(\"\\nVALID EMAILS FOUND:\")\n",
    "for email in valid_emails:\n",
    "    print(\" -\", email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9ce95-3547-4d79-96e3-0090496d0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part3\n",
    "## Obtain the synsets of a particular object and display its definitions and the hypnonyms from its second definition.\n",
    "# Using two of the hyponyms, generate some sample data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0b9089c-322d-4cad-a663-6c2248d9d8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\usaas\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Definition of 'car':\n",
      "a wheeled vehicle adapted to the rails of railroad\n",
      "\n",
      "Hyponyms from 2nd Definition:\n",
      "- tender\n",
      "- cabin_car\n",
      "- mail_car\n",
      "- passenger_car\n",
      "- guard's_van\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hyponyms[:\u001b[38;5;241m5\u001b[39m]:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m, h\u001b[38;5;241m.\u001b[39mname()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 18\u001b[0m a\n\u001b[0;32m     19\u001b[0m hypo1 \u001b[38;5;241m=\u001b[39m hyponyms[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     20\u001b[0m hypo2 \u001b[38;5;241m=\u001b[39m hyponyms[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mname()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "word = \"car\"\n",
    "synsets = wn.synsets(word)\n",
    "\n",
    "second_def = synsets[1].definition()\n",
    "print(\"Second Definition of 'car':\")\n",
    "print(second_def)\n",
    "\n",
    "hyponyms = synsets[1].hyponyms()\n",
    "print(\"\\nHyponyms from 2nd Definition:\")\n",
    "for h in hyponyms[:5]:\n",
    "    print(\"-\", h.name().split('.')[0])\n",
    "a\n",
    "hypo1 = hyponyms[0].name().split('.')[0]\n",
    "hypo2 = hyponyms[1].name().split('.')[0]\n",
    "\n",
    "data = {\n",
    "    hypo1: ['Model A', 'Model B', 'Model C'],\n",
    "    hypo2: ['Version X', 'Version Y', 'Version Z']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\nSample Data from Two Hyponyms:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be2393-5c86-4e07-863d-ff976035efce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
